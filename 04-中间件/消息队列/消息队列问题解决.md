# æ¶ˆæ¯é˜Ÿåˆ— - é—®é¢˜è§£å†³

---
tags: [é—®é¢˜è§£å†³, æ¶ˆæ¯é˜Ÿåˆ—, MQ, Kafka, RabbitMQ, æ€§èƒ½ä¼˜åŒ–]
created: 2026-02-21
updated: 2026-02-21
status: æŒç»­æ›´æ–°
importance: â­â­â­â­
---

## ğŸš¨ é«˜é¢‘é—®é¢˜é€ŸæŸ¥

### é—®é¢˜1ï¼šæ¶ˆæ¯ä¸¢å¤± `#æ¶ˆæ¯ä¸¢å¤±`
**ç°è±¡**ï¼šç”Ÿäº§è€…å‘é€çš„æ¶ˆæ¯æ²¡æœ‰è¢«æ¶ˆè´¹è€…æ¥æ”¶åˆ°
**åŸå› **ï¼šç½‘ç»œå¼‚å¸¸ã€Brokerå®•æœºã€æ¶ˆè´¹è€…å¤„ç†å¼‚å¸¸ç­‰
**è§£å†³**ï¼š
1. å¯ç”¨ç”Ÿäº§è€…ç¡®è®¤æœºåˆ¶
2. è®¾ç½®åˆé€‚çš„å‰¯æœ¬æ•°é‡
3. ä½¿ç”¨æ‰‹åŠ¨ç¡®è®¤æ¶ˆè´¹
4. å®ç°æ¶ˆæ¯æŒä¹…åŒ–

```java
// ç”Ÿäº§è€…ç¡®è®¤é…ç½®
@Bean
public ProducerFactory<String, Object> producerFactory() {
    Map<String, Object> props = new HashMap<>();
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    props.put(ProducerConfig.ACKS_CONFIG, "all"); // ç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
    props.put(ProducerConfig.RETRIES_CONFIG, 3); // é‡è¯•æ¬¡æ•°
    props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true); // å¹‚ç­‰æ€§
    return new DefaultKafkaProducerFactory<>(props);
}

// æ¶ˆè´¹è€…æ‰‹åŠ¨ç¡®è®¤
@KafkaListener(topics = "test-topic")
public void consume(String message, Acknowledgment ack) {
    try {
        processMessage(message);
        ack.acknowledge(); // æ‰‹åŠ¨ç¡®è®¤
    } catch (Exception e) {
        // å¤„ç†å¤±è´¥ï¼Œä¸ç¡®è®¤ï¼Œæ¶ˆæ¯ä¼šé‡æ–°æŠ•é€’
        log.error("æ¶ˆæ¯å¤„ç†å¤±è´¥: {}", message, e);
    }
}
```

**ç›¸å…³åŸç†**ï¼š[[æ¶ˆæ¯é˜Ÿåˆ—åŸç†#å¯é ä¼ è¾“]]

---

### é—®é¢˜2ï¼šæ¶ˆæ¯é‡å¤æ¶ˆè´¹ `#é‡å¤æ¶ˆè´¹`
**ç°è±¡**ï¼šåŒä¸€æ¡æ¶ˆæ¯è¢«æ¶ˆè´¹è€…å¤„ç†å¤šæ¬¡
**åŸå› **ï¼šç½‘ç»œæŠ–åŠ¨ã€æ¶ˆè´¹è€…é‡å¯ã€ç¡®è®¤è¶…æ—¶ç­‰
**è§£å†³**ï¼š
1. å®ç°å¹‚ç­‰æ€§å¤„ç†
2. ä½¿ç”¨å”¯ä¸€æ¶ˆæ¯ID
3. æ•°æ®åº“å”¯ä¸€çº¦æŸ
4. Rediså»é‡

```java
@Service
public class IdempotentMessageProcessor {

    @Autowired
    private RedisTemplate<String, String> redisTemplate;

    @KafkaListener(topics = "order-topic")
    public void processOrder(OrderMessage message) {
        String messageId = message.getMessageId();
        String lockKey = "msg_lock:" + messageId;

        // ä½¿ç”¨Rediså®ç°åˆ†å¸ƒå¼é”å’Œå»é‡
        Boolean lockAcquired = redisTemplate.opsForValue()
            .setIfAbsent(lockKey, "1", Duration.ofMinutes(5));

        if (!lockAcquired) {
            log.info("æ¶ˆæ¯å·²å¤„ç†ï¼Œè·³è¿‡: {}", messageId);
            return;
        }

        try {
            // æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦å·²å¤„ç†
            if (isMessageProcessed(messageId)) {
                log.info("æ¶ˆæ¯å·²å¤„ç†: {}", messageId);
                return;
            }

            // å¤„ç†ä¸šåŠ¡é€»è¾‘
            processBusinessLogic(message);

            // æ ‡è®°æ¶ˆæ¯å·²å¤„ç†
            markMessageProcessed(messageId);

        } finally {
            redisTemplate.delete(lockKey);
        }
    }

    private boolean isMessageProcessed(String messageId) {
        return redisTemplate.hasKey("processed:" + messageId);
    }

    private void markMessageProcessed(String messageId) {
        redisTemplate.opsForValue().set("processed:" + messageId, "1",
            Duration.ofDays(7));
    }
}
```

---

### é—®é¢˜3ï¼šæ¶ˆæ¯ç§¯å‹ `#æ¶ˆæ¯ç§¯å‹`
**ç°è±¡**ï¼šæ¶ˆæ¯é˜Ÿåˆ—ä¸­ç§¯å‹å¤§é‡æœªå¤„ç†æ¶ˆæ¯
**åŸå› **ï¼šæ¶ˆè´¹è€…å¤„ç†é€Ÿåº¦æ…¢ã€æ¶ˆè´¹è€…æ•°é‡ä¸è¶³ã€æ¶ˆè´¹è€…å®•æœº
**è§£å†³**ï¼š
1. å¢åŠ æ¶ˆè´¹è€…æ•°é‡
2. ä¼˜åŒ–æ¶ˆè´¹è€…å¤„ç†é€»è¾‘
3. å¢åŠ åˆ†åŒºæ•°é‡
4. æ‰¹é‡å¤„ç†æ¶ˆæ¯

```java
// å¢åŠ æ¶ˆè´¹è€…å¹¶å‘æ•°
@Bean
public ConcurrentKafkaListenerContainerFactory<String, String>
        kafkaListenerContainerFactory() {
    ConcurrentKafkaListenerContainerFactory<String, String> factory =
            new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(consumerFactory());
    factory.setConcurrency(10); // å¢åŠ å¹¶å‘æ¶ˆè´¹è€…æ•°é‡
    return factory;
}

// æ‰¹é‡æ¶ˆè´¹ä¼˜åŒ–
@KafkaListener(topics = "batch-topic",
               containerFactory = "batchKafkaListenerContainerFactory")
public void consumeBatch(List<OrderMessage> messages) {
    // æ‰¹é‡å¤„ç†ï¼Œæé«˜æ•ˆç‡
    List<Order> orders = messages.stream()
        .map(this::convertToOrder)
        .collect(Collectors.toList());

    orderService.batchSave(orders);
}

// å¼‚æ­¥å¤„ç†
@KafkaListener(topics = "async-topic")
public void consumeAsync(String message) {
    CompletableFuture.runAsync(() -> {
        processMessage(message);
    }, taskExecutor);
}
```

---

### é—®é¢˜4ï¼šæ¶ˆæ¯é¡ºåºæ€§é—®é¢˜ `#æ¶ˆæ¯é¡ºåº`
**ç°è±¡**ï¼šéœ€è¦ä¿è¯æ¶ˆæ¯é¡ºåºå¤„ç†ï¼Œä½†æ¶ˆæ¯ä¹±åº
**åŸå› **ï¼šå¤šåˆ†åŒºã€å¤šæ¶ˆè´¹è€…å¹¶å‘å¤„ç†
**è§£å†³**ï¼š
1. å•åˆ†åŒºå•æ¶ˆè´¹è€…
2. æŒ‰ä¸šåŠ¡keyåˆ†åŒº
3. æ¶ˆè´¹è€…å†…éƒ¨æ’é˜Ÿå¤„ç†

```java
// è‡ªå®šä¹‰åˆ†åŒºå™¨ä¿è¯é¡ºåº
public class OrderPartitioner implements Partitioner {
    @Override
    public int partition(String topic, Object key, byte[] keyBytes,
                        Object value, byte[] valueBytes, Cluster cluster) {
        if (key == null) {
            return 0;
        }

        // æ ¹æ®ç”¨æˆ·IDåˆ†åŒºï¼Œä¿è¯åŒä¸€ç”¨æˆ·çš„æ¶ˆæ¯æœ‰åº
        String userId = extractUserId(key.toString());
        return Math.abs(userId.hashCode()) % cluster.partitionCountForTopic(topic);
    }
}

// æ¶ˆè´¹è€…å†…éƒ¨æ’é˜Ÿå¤„ç†
@Component
public class OrderedMessageProcessor {

    private final Map<String, BlockingQueue<Message>> userQueues = new ConcurrentHashMap<>();
    private final ExecutorService executor = Executors.newFixedThreadPool(10);

    @KafkaListener(topics = "ordered-topic")
    public void consume(OrderMessage message) {
        String userId = message.getUserId();

        // ä¸ºæ¯ä¸ªç”¨æˆ·ç»´æŠ¤ä¸€ä¸ªé˜Ÿåˆ—
        BlockingQueue<Message> queue = userQueues.computeIfAbsent(userId,
            k -> new LinkedBlockingQueue<>());

        queue.offer(message);

        // å¼‚æ­¥å¤„ç†é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
        executor.submit(() -> processUserQueue(userId, queue));
    }

    private void processUserQueue(String userId, BlockingQueue<Message> queue) {
        try {
            Message message = queue.take();
            processMessage(message);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }
}
```

---

### é—®é¢˜5ï¼šæ­»ä¿¡é˜Ÿåˆ—å¤„ç† `#æ­»ä¿¡é˜Ÿåˆ—`
**ç°è±¡**ï¼šæ¶ˆæ¯å¤„ç†å¤±è´¥åæ— æ³•æ­£å¸¸æ¶ˆè´¹
**åŸå› **ï¼šæ¶ˆæ¯æ ¼å¼é”™è¯¯ã€ä¸šåŠ¡é€»è¾‘å¼‚å¸¸ã€ä¾èµ–æœåŠ¡ä¸å¯ç”¨
**è§£å†³**ï¼š
1. é…ç½®æ­»ä¿¡é˜Ÿåˆ—
2. å®ç°é‡è¯•æœºåˆ¶
3. ç›‘æ§å’Œå‘Šè­¦

```java
// RabbitMQæ­»ä¿¡é˜Ÿåˆ—é…ç½®
@Configuration
public class DeadLetterQueueConfig {

    @Bean
    public Queue businessQueue() {
        return QueueBuilder.durable("business.queue")
                .withArgument("x-dead-letter-exchange", "dlx.exchange")
                .withArgument("x-dead-letter-routing-key", "dlx.routing.key")
                .withArgument("x-message-ttl", 300000) // 5åˆ†é’ŸTTL
                .build();
    }

    @Bean
    public Queue deadLetterQueue() {
        return QueueBuilder.durable("dead.letter.queue").build();
    }

    @Bean
    public DirectExchange deadLetterExchange() {
        return new DirectExchange("dlx.exchange");
    }

    @RabbitListener(queues = "dead.letter.queue")
    public void handleDeadLetter(String message,
                                @Header Map<String, Object> headers) {
        log.error("æ”¶åˆ°æ­»ä¿¡æ¶ˆæ¯: {}, headers: {}", message, headers);

        // åˆ†æå¤±è´¥åŸå› 
        String failureReason = analyzeFailure(message, headers);

        // è®°å½•åˆ°æ•°æ®åº“æˆ–å‘é€å‘Šè­¦
        deadLetterService.recordDeadLetter(message, failureReason);

        // æ ¹æ®æƒ…å†µå†³å®šæ˜¯å¦é‡æ–°æŠ•é€’
        if (shouldRetry(failureReason)) {
            retryMessage(message);
        }
    }
}

// Kafkaé‡è¯•æœºåˆ¶
@Component
public class RetryableMessageProcessor {

    private static final int MAX_RETRY_COUNT = 3;

    @KafkaListener(topics = "retry-topic")
    public void processWithRetry(String message,
                               @Header(required = false) Integer retryCount) {
        int currentRetry = retryCount != null ? retryCount : 0;

        try {
            processMessage(message);
        } catch (Exception e) {
            if (currentRetry < MAX_RETRY_COUNT) {
                // é‡æ–°å‘é€åˆ°é‡è¯•é˜Ÿåˆ—
                sendToRetryQueue(message, currentRetry + 1);
            } else {
                // å‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—
                sendToDeadLetterQueue(message, e);
            }
        }
    }

    private void sendToRetryQueue(String message, int retryCount) {
        kafkaTemplate.send("retry-topic", message)
            .addCallback(result -> {
                // æ·»åŠ é‡è¯•è®¡æ•°å¤´
                result.getProducerRecord().headers()
                    .add("retryCount", String.valueOf(retryCount).getBytes());
            }, failure -> {
                log.error("é‡è¯•æ¶ˆæ¯å‘é€å¤±è´¥", failure);
            });
    }
}
```

## ğŸ”§ è°ƒè¯•æŠ€å·§

### å¸¸ç”¨è°ƒè¯•æ–¹æ³•

#### 1. æ¶ˆæ¯è¿½è¸ª
```java
@Component
public class MessageTracker {

    @EventListener
    public void handleProducerEvent(ProducerEvent event) {
        log.info("æ¶ˆæ¯å‘é€: topic={}, key={}, partition={}, offset={}",
            event.getTopic(), event.getKey(),
            event.getPartition(), event.getOffset());
    }

    @EventListener
    public void handleConsumerEvent(ConsumerEvent event) {
        log.info("æ¶ˆæ¯æ¶ˆè´¹: topic={}, partition={}, offset={}, lag={}",
            event.getTopic(), event.getPartition(),
            event.getOffset(), event.getLag());
    }
}

// è‡ªå®šä¹‰æ‹¦æˆªå™¨
public class MessageInterceptor implements ProducerInterceptor<String, Object> {

    @Override
    public ProducerRecord<String, Object> onSend(ProducerRecord<String, Object> record) {
        // æ·»åŠ è¿½è¸ªID
        String traceId = UUID.randomUUID().toString();
        record.headers().add("traceId", traceId.getBytes());

        log.info("å‘é€æ¶ˆæ¯: traceId={}, topic={}, key={}",
            traceId, record.topic(), record.key());

        return record;
    }

    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
        if (exception != null) {
            log.error("æ¶ˆæ¯å‘é€å¤±è´¥: {}", metadata, exception);
        } else {
            log.info("æ¶ˆæ¯å‘é€æˆåŠŸ: {}", metadata);
        }
    }
}
```

#### 2. æ€§èƒ½ç›‘æ§
```java
@Component
public class KafkaMetrics {

    private final MeterRegistry meterRegistry;
    private final Counter messagesSent;
    private final Counter messagesReceived;
    private final Timer processingTime;

    public KafkaMetrics(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
        this.messagesSent = Counter.builder("kafka.messages.sent")
            .register(meterRegistry);
        this.messagesReceived = Counter.builder("kafka.messages.received")
            .register(meterRegistry);
        this.processingTime = Timer.builder("kafka.processing.time")
            .register(meterRegistry);
    }

    @EventListener
    public void onMessageSent(MessageSentEvent event) {
        messagesSent.increment(
            Tags.of("topic", event.getTopic(),
                   "status", event.isSuccess() ? "success" : "failure"));
    }

    @EventListener
    public void onMessageReceived(MessageReceivedEvent event) {
        messagesReceived.increment(
            Tags.of("topic", event.getTopic(),
                   "consumer.group", event.getConsumerGroup()));

        processingTime.record(event.getProcessingTime(), TimeUnit.MILLISECONDS);
    }
}
```

### æ€§èƒ½åˆ†æå·¥å…·

#### 1. JMXç›‘æ§
```java
@Configuration
public class KafkaJmxConfig {

    @Bean
    public MBeanExporter kafkaMBeanExporter() {
        MBeanExporter exporter = new MBeanExporter();
        exporter.setDefaultDomain("kafka");
        return exporter;
    }

    @ManagedResource(objectName = "kafka:type=Producer,name=MessageProducer")
    @Component
    public static class ProducerMetrics {

        private final AtomicLong messagesSent = new AtomicLong(0);
        private final AtomicLong messagesFailure = new AtomicLong(0);

        @ManagedAttribute
        public long getMessagesSent() {
            return messagesSent.get();
        }

        @ManagedAttribute
        public long getMessagesFailure() {
            return messagesFailure.get();
        }

        @ManagedOperation
        public void resetCounters() {
            messagesSent.set(0);
            messagesFailure.set(0);
        }

        public void incrementSent() {
            messagesSent.incrementAndGet();
        }

        public void incrementFailure() {
            messagesFailure.incrementAndGet();
        }
    }
}
```

#### 2. å¥åº·æ£€æŸ¥
```java
@Component
public class KafkaHealthIndicator implements HealthIndicator {

    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;

    @Override
    public Health health() {
        try {
            // å‘é€æµ‹è¯•æ¶ˆæ¯
            ListenableFuture<SendResult<String, Object>> future =
                kafkaTemplate.send("health-check", "ping");

            SendResult<String, Object> result = future.get(5, TimeUnit.SECONDS);

            return Health.up()
                .withDetail("kafka.cluster", "available")
                .withDetail("test.message.sent", true)
                .withDetail("partition", result.getRecordMetadata().partition())
                .build();

        } catch (Exception e) {
            return Health.down()
                .withDetail("kafka.cluster", "unavailable")
                .withDetail("error", e.getMessage())
                .build();
        }
    }
}
```

## ğŸ”— ç›¸å…³æ–‡æ¡£

- **æŠ€æœ¯åŸç†**ï¼š[[æ¶ˆæ¯é˜Ÿåˆ—åŸç†]] [[Kafkaå®æˆ˜]]
- **å®æˆ˜åº”ç”¨**ï¼š[[å¾®æœåŠ¡é€šä¿¡]] [[äº‹ä»¶é©±åŠ¨æ¶æ„]]

## ğŸ·ï¸ æ ‡ç­¾
#é—®é¢˜è§£å†³ #æ¶ˆæ¯é˜Ÿåˆ— #Kafka #RabbitMQ #æ€§èƒ½ä¼˜åŒ– #ç›‘æ§